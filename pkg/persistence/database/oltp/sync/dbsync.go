package sync

import (
	"context"
	"errors"
	"fmt"
	"sync"
	"time"

	"github.com/digitalwayhk/core/pkg/persistence/database/oltp"
	"github.com/zeromicro/go-zero/core/logx"
	"gorm.io/gorm"
)

// åŒæ­¥çŠ¶æ€
type SyncStatus int

const (
	SyncStatusIdle SyncStatus = iota
	SyncStatusRunning
	SyncStatusPaused
	SyncStatusError
)

// åŒæ­¥æ–¹å‘
type SyncDirection int

const (
	SyncToRemote SyncDirection = iota
	SyncFromRemote
	SyncBoth
)

// å†²çªå¤„ç†æ¨¡å¼
type ConflictMode int

const (
	ConflictModeSkip      ConflictMode = iota // è·³è¿‡å†²çª
	ConflictModeOverwrite                     // è¦†ç›–
	ConflictModeNewest                        // ä¿ç•™æœ€æ–°
)

// åŒæ­¥é…ç½®
type SyncConfig struct {
	// åŸºç¡€é…ç½®
	Interval      time.Duration // åŒæ­¥é—´éš”
	BatchSize     int           // æ‰¹é‡å¤§å°
	MaxRetries    int           // æœ€å¤§é‡è¯•æ¬¡æ•°
	RetryInterval time.Duration // é‡è¯•é—´éš”
	Direction     SyncDirection // åŒæ­¥æ–¹å‘

	// MySQL é…ç½®
	MySQLHost string
	MySQLPort uint
	MySQLUser string
	MySQLPass string

	// è¿‡æ»¤å™¨
	TableFilter   func(tableName string) bool   // è¡¨è¿‡æ»¤å™¨
	RecordFilter  func(record interface{}) bool // è®°å½•è¿‡æ»¤å™¨
	ConflictMode  ConflictMode                  // å†²çªå¤„ç†æ¨¡å¼
	EnableLogging bool                          // æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—
}

// åŒæ­¥ç®¡ç†å™¨
type DBSyncManager struct {
	config      *SyncConfig
	mysql       *oltp.Mysql
	status      SyncStatus
	lastError   error
	stats       *SyncStats
	mu          sync.RWMutex
	ctx         context.Context
	cancel      context.CancelFunc
	changeLog   *ChangeLog
	syncTrigger chan struct{}
}

// åŒæ­¥ç»Ÿè®¡
type SyncStats struct {
	mu            sync.RWMutex
	TotalSynced   int64
	FailedSynced  int64
	ToRemote      int64
	FromRemote    int64
	LastSyncTime  time.Time
	LastSyncError error
}

func (s *SyncStats) IncrementSuccess(direction SyncDirection) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.TotalSynced++
	s.LastSyncTime = time.Now()
	if direction == SyncToRemote {
		s.ToRemote++
	} else if direction == SyncFromRemote {
		s.FromRemote++
	}
}

func (s *SyncStats) IncrementFailed() {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.FailedSynced++
}

func (s *SyncStats) SetError(err error) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.LastSyncError = err
}

func (s *SyncStats) GetStats() (total, failed, toRemote, fromRemote int64, lastSync time.Time) {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return s.TotalSynced, s.FailedSynced, s.ToRemote, s.FromRemote, s.LastSyncTime
}

// åˆ›å»ºåŒæ­¥ç®¡ç†å™¨
func NewDBSyncManager(config *SyncConfig) (*DBSyncManager, error) {
	if config == nil {
		return nil, errors.New("sync config is required")
	}

	// è®¾ç½®é»˜è®¤å€¼
	if config.Interval == 0 {
		config.Interval = 5 * time.Minute
	}
	if config.BatchSize == 0 {
		config.BatchSize = 100
	}
	if config.MaxRetries == 0 {
		config.MaxRetries = 3
	}
	if config.RetryInterval == 0 {
		config.RetryInterval = 30 * time.Second
	}

	// åˆ›å»º MySQL è¿æ¥
	mysql := oltp.NewMysql(
		config.MySQLHost,
		config.MySQLUser,
		config.MySQLPass,
		config.MySQLPort,
		config.EnableLogging,
		true,
	)

	ctx, cancel := context.WithCancel(context.Background())

	manager := &DBSyncManager{
		config:      config,
		mysql:       mysql,
		status:      SyncStatusIdle,
		stats:       &SyncStats{},
		ctx:         ctx,
		cancel:      cancel,
		changeLog:   NewChangeLog(),
		syncTrigger: make(chan struct{}, 1),
	}

	return manager, nil
}

// ğŸ”§ æ ¸å¿ƒæ–¹æ³•ï¼šä» ConnectionManager è·å–æ‰€æœ‰ SQLite æ•°æ®åº“å¹¶åŒæ­¥
func (m *DBSyncManager) syncAllDatabases() error {
	// ä» ConnectionManager è·å–æ‰€æœ‰è¿æ¥
	connManager := oltp.GetConnectionManager()
	connections := connManager.GetAllConnections()

	if len(connections) == 0 {
		logx.Info("ğŸ“­ æ²¡æœ‰æ‰¾åˆ° SQLite æ•°æ®åº“")
		return nil
	}

	logx.Infof("ğŸ” å‘ç° %d ä¸ªæ•°æ®åº“è¿æ¥", len(connections))

	successCount := 0
	failCount := 0

	// éå†æ‰€æœ‰è¿æ¥
	for dbKey, connInfo := range connections {
		// ğŸ”§ å°è¯•ä»æ•°æ®åº“ä¸­è¯»å–ä»»æ„è¡¨çš„æ¨¡å‹æ¥è·å– IDBName
		localDBName, remoteDBName, err := m.getDBNamesFromConnection(connInfo.DB, dbKey)
		if err != nil {
			logx.Errorf("âš ï¸  æ— æ³•è·å–æ•°æ®åº“åç§°æ˜ å°„ [%s]: %v", dbKey, err)
			// ä½¿ç”¨é»˜è®¤æ˜ å°„
			localDBName = dbKey
			remoteDBName = dbKey
		}

		logx.Infof("ğŸ”„ åŒæ­¥æ•°æ®åº“: %s -> %s", localDBName, remoteDBName)

		// æ ¹æ®åŒæ­¥æ–¹å‘æ‰§è¡ŒåŒæ­¥
		switch m.config.Direction {
		case SyncToRemote:
			if err := m.syncToRemote(connInfo.DB, localDBName, remoteDBName); err != nil {
				logx.Errorf("âŒ åŒæ­¥åˆ°è¿œç¨‹å¤±è´¥ [%s]: %v", localDBName, err)
				m.stats.IncrementFailed()
				m.stats.SetError(err)
				failCount++
			} else {
				successCount++
			}

		case SyncFromRemote:
			if err := m.syncFromRemote(connInfo.DB, localDBName, remoteDBName); err != nil {
				logx.Errorf("âŒ ä»è¿œç¨‹åŒæ­¥å¤±è´¥ [%s]: %v", localDBName, err)
				m.stats.IncrementFailed()
				m.stats.SetError(err)
				failCount++
			} else {
				successCount++
			}

		case SyncBoth:
			// å…ˆä»è¿œç¨‹åŒæ­¥ï¼Œå†åŒæ­¥åˆ°è¿œç¨‹
			if err := m.syncFromRemote(connInfo.DB, localDBName, remoteDBName); err != nil {
				logx.Errorf("âŒ ä»è¿œç¨‹åŒæ­¥å¤±è´¥ [%s]: %v", localDBName, err)
				m.stats.IncrementFailed()
				failCount++
			}
			if err := m.syncToRemote(connInfo.DB, localDBName, remoteDBName); err != nil {
				logx.Errorf("âŒ åŒæ­¥åˆ°è¿œç¨‹å¤±è´¥ [%s]: %v", localDBName, err)
				m.stats.IncrementFailed()
				failCount++
			}
			if err == nil {
				successCount++
			}
		}
	}

	logx.Infof("âœ… åŒæ­¥å®Œæˆ: æˆåŠŸ %d, å¤±è´¥ %d", successCount, failCount)
	return nil
}

// ğŸ”§ ä»æ•°æ®åº“è¿æ¥ä¸­è·å–æœ¬åœ°å’Œè¿œç¨‹æ•°æ®åº“å
func (m *DBSyncManager) getDBNamesFromConnection(db *gorm.DB, defaultName string) (localName, remoteName string, err error) {
	// æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨
	var tables []struct {
		Name string
	}

	err = db.Raw("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%' LIMIT 1").Scan(&tables).Error
	if err != nil || len(tables) == 0 {
		return defaultName, defaultName, fmt.Errorf("æ— æ³•æŸ¥è¯¢è¡¨")
	}

	// å°è¯•ä»ç¬¬ä¸€ä¸ªè¡¨ä¸­è¯»å–ä¸€æ¡è®°å½•
	var records []map[string]interface{}
	err = db.Table(tables[0].Name).Limit(1).Find(&records).Error
	if err != nil || len(records) == 0 {
		return defaultName, defaultName, fmt.Errorf("æ— æ³•è¯»å–æ•°æ®")
	}

	// ğŸ”§ æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥è·å– IDBName å®ä¾‹
	// æ‰€ä»¥é‡‡ç”¨çº¦å®šï¼šä½¿ç”¨æ•°æ®åº“æ–‡ä»¶è·¯å¾„ä½œä¸ºæœ¬åœ°åï¼Œè¿œç¨‹åéœ€è¦å¦å¤–é…ç½®
	return defaultName, defaultName, nil
}

// ğŸ”§ åŒæ­¥åˆ°è¿œç¨‹ (SQLite -> MySQL)
func (m *DBSyncManager) syncToRemote(sqlite *gorm.DB, localDBName, remoteDBName string) error {
	// æŸ¥è¯¢æ‰€æœ‰è¡¨
	var tables []struct {
		Name string
	}
	err := sqlite.Raw("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'").Scan(&tables).Error
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢è¡¨åˆ—è¡¨å¤±è´¥: %v", err)
	}

	if len(tables) == 0 {
		logx.Infof("ğŸ“­ SQLite æ— è¡¨ [%s]", localDBName)
		return nil
	}

	// è®¾ç½® MySQL æ•°æ®åº“å
	m.mysql.Name = remoteDBName
	mysqlDB, err := m.mysql.GetDB()
	if err != nil {
		return fmt.Errorf("è·å– MySQL è¿æ¥å¤±è´¥: %v", err)
	}

	// åŒæ­¥æ¯ä¸ªè¡¨
	for _, table := range tables {
		// åº”ç”¨è¡¨è¿‡æ»¤å™¨
		if m.config.TableFilter != nil && !m.config.TableFilter(table.Name) {
			logx.Infof("â­ï¸  è·³è¿‡è¡¨ [%s] (è¢«è¿‡æ»¤)", table.Name)
			continue
		}

		if err := m.syncTableToRemote(sqlite, mysqlDB, table.Name, localDBName); err != nil {
			logx.Errorf("åŒæ­¥è¡¨åˆ°è¿œç¨‹å¤±è´¥ [%s.%s]: %v", localDBName, table.Name, err)
			continue
		}

		m.stats.IncrementSuccess(SyncToRemote)
	}

	return nil
}

// ğŸ”§ ä»è¿œç¨‹åŒæ­¥ (MySQL -> SQLite)
func (m *DBSyncManager) syncFromRemote(sqlite *gorm.DB, localDBName, remoteDBName string) error {
	// è®¾ç½® MySQL æ•°æ®åº“å
	m.mysql.Name = remoteDBName
	mysqlDB, err := m.mysql.GetDB()
	if err != nil {
		return fmt.Errorf("è·å– MySQL è¿æ¥å¤±è´¥: %v", err)
	}

	// è·å– MySQL ä¸­çš„æ‰€æœ‰è¡¨
	var tables []struct {
		TableName string `gorm:"column:TABLE_NAME"`
	}

	err = mysqlDB.Raw("SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA=?", remoteDBName).Scan(&tables).Error
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢ MySQL è¡¨åˆ—è¡¨å¤±è´¥: %v", err)
	}

	if len(tables) == 0 {
		logx.Infof("ğŸ“­ MySQL æ— è¡¨ [%s]", remoteDBName)
		return nil
	}

	// åŒæ­¥æ¯ä¸ªè¡¨
	for _, table := range tables {
		// åº”ç”¨è¡¨è¿‡æ»¤å™¨
		if m.config.TableFilter != nil && !m.config.TableFilter(table.TableName) {
			logx.Infof("â­ï¸  è·³è¿‡è¡¨ [%s] (è¢«è¿‡æ»¤)", table.TableName)
			continue
		}

		if err := m.syncTableFromRemote(sqlite, mysqlDB, table.TableName, localDBName); err != nil {
			logx.Errorf("ä»è¿œç¨‹åŒæ­¥è¡¨å¤±è´¥ [%s.%s]: %v", localDBName, table.TableName, err)
			continue
		}

		m.stats.IncrementSuccess(SyncFromRemote)
	}

	return nil
}

// åŒæ­¥å•ä¸ªè¡¨åˆ°è¿œç¨‹
func (m *DBSyncManager) syncTableToRemote(sqlite, mysql *gorm.DB, tableName, localDBName string) error {
	var records []map[string]interface{}
	err := sqlite.Table(tableName).Limit(m.config.BatchSize).Find(&records).Error
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢ SQLite æ•°æ®å¤±è´¥: %v", err)
	}

	if len(records) == 0 {
		return nil
	}

	synced := 0
	for _, record := range records {
		// åº”ç”¨è®°å½•è¿‡æ»¤å™¨
		if m.config.RecordFilter != nil && !m.config.RecordFilter(record) {
			continue
		}

		// æ ¹æ®å†²çªæ¨¡å¼å¤„ç†
		if err := m.insertOrUpdateRemote(mysql, tableName, record); err != nil {
			logx.Errorf("æ’å…¥è¿œç¨‹è®°å½•å¤±è´¥ [%s]: %v", tableName, err)
			continue
		}
		synced++
	}

	if synced > 0 {
		logx.Infof("âœ… åŒæ­¥è¡¨åˆ°è¿œç¨‹ [%s]: %d/%d æ¡è®°å½•", tableName, synced, len(records))
	}
	return nil
}

// ä»è¿œç¨‹åŒæ­¥å•ä¸ªè¡¨
func (m *DBSyncManager) syncTableFromRemote(sqlite, mysql *gorm.DB, tableName, localDBName string) error {
	var records []map[string]interface{}
	err := mysql.Table(tableName).Limit(m.config.BatchSize).Find(&records).Error
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢ MySQL æ•°æ®å¤±è´¥: %v", err)
	}

	if len(records) == 0 {
		return nil
	}

	synced := 0
	for _, record := range records {
		// åº”ç”¨è®°å½•è¿‡æ»¤å™¨
		if m.config.RecordFilter != nil && !m.config.RecordFilter(record) {
			continue
		}

		// æ’å…¥æˆ–æ›´æ–° SQLite
		if err := m.insertOrUpdateLocal(sqlite, tableName, record); err != nil {
			logx.Errorf("æ’å…¥æœ¬åœ°è®°å½•å¤±è´¥ [%s]: %v", tableName, err)
			continue
		}
		synced++
	}

	if synced > 0 {
		logx.Infof("âœ… ä»è¿œç¨‹åŒæ­¥è¡¨ [%s]: %d/%d æ¡è®°å½•", tableName, synced, len(records))
	}
	return nil
}

// æ’å…¥æˆ–æ›´æ–°è¿œç¨‹è®°å½•
func (m *DBSyncManager) insertOrUpdateRemote(db *gorm.DB, tableName string, record map[string]interface{}) error {
	switch m.config.ConflictMode {
	case ConflictModeSkip:
		return db.Table(tableName).Create(record).Error
	case ConflictModeOverwrite:
		return db.Table(tableName).Save(record).Error
	case ConflictModeNewest:
		return m.upsertByTimestamp(db, tableName, record)
	default:
		return db.Table(tableName).Create(record).Error
	}
}

// æ’å…¥æˆ–æ›´æ–°æœ¬åœ°è®°å½•
func (m *DBSyncManager) insertOrUpdateLocal(db *gorm.DB, tableName string, record map[string]interface{}) error {
	switch m.config.ConflictMode {
	case ConflictModeSkip:
		return db.Table(tableName).Create(record).Error
	case ConflictModeOverwrite:
		return db.Table(tableName).Save(record).Error
	case ConflictModeNewest:
		return m.upsertByTimestamp(db, tableName, record)
	default:
		return db.Table(tableName).Create(record).Error
	}
}

// æ ¹æ®æ—¶é—´æˆ³æ›´æ–°
func (m *DBSyncManager) upsertByTimestamp(db *gorm.DB, tableName string, record map[string]interface{}) error {
	// æ£€æŸ¥æ˜¯å¦æœ‰ updated_at å­—æ®µ
	if _, ok := record["updated_at"]; !ok {
		// æ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½¿ç”¨ Save
		return db.Table(tableName).Save(record).Error
	}

	// æŸ¥è¯¢ç°æœ‰è®°å½•
	var existing map[string]interface{}
	if id, ok := record["id"]; ok {
		err := db.Table(tableName).Where("id = ?", id).First(&existing).Error
		if err == gorm.ErrRecordNotFound {
			// è®°å½•ä¸å­˜åœ¨ï¼Œç›´æ¥åˆ›å»º
			return db.Table(tableName).Create(record).Error
		}
		if err != nil {
			return err
		}

		// æ¯”è¾ƒæ—¶é—´æˆ³
		if existingTime, ok := existing["updated_at"].(time.Time); ok {
			if recordTime, ok := record["updated_at"].(time.Time); ok {
				if recordTime.After(existingTime) {
					// æ–°è®°å½•æ›´æ–°ï¼Œæ›´æ–°æ•°æ®åº“
					return db.Table(tableName).Save(record).Error
				}
				// æ—§è®°å½•ï¼Œè·³è¿‡
				return nil
			}
		}
	}

	// é»˜è®¤ä½¿ç”¨ Save
	return db.Table(tableName).Save(record).Error
}

// å¯åŠ¨åŒæ­¥æœåŠ¡
func (m *DBSyncManager) Start() error {
	m.mu.Lock()
	if m.status == SyncStatusRunning {
		m.mu.Unlock()
		return errors.New("sync manager already running")
	}
	m.status = SyncStatusRunning
	m.mu.Unlock()

	logx.Info("ğŸš€ å¯åŠ¨æ•°æ®åº“åŒæ­¥æœåŠ¡...")

	go m.syncLoop()
	return nil
}

// åŒæ­¥å¾ªç¯
func (m *DBSyncManager) syncLoop() {
	ticker := time.NewTicker(m.config.Interval)
	defer ticker.Stop()

	for {
		select {
		case <-m.ctx.Done():
			return
		case <-ticker.C:
			m.performSync()
		case <-m.syncTrigger:
			// æ‰‹åŠ¨è§¦å‘åŒæ­¥
			m.performSync()
		}
	}
}

// æ‰§è¡ŒåŒæ­¥
func (m *DBSyncManager) performSync() {
	m.mu.RLock()
	if m.status == SyncStatusPaused {
		m.mu.RUnlock()
		return
	}
	m.mu.RUnlock()

	startTime := time.Now()
	logx.Info("ğŸ”„ å¼€å§‹æ•°æ®åº“åŒæ­¥...")

	if err := m.syncAllDatabases(); err != nil {
		logx.Errorf("âŒ åŒæ­¥å¤±è´¥: %v", err)
		m.mu.Lock()
		m.status = SyncStatusError
		m.lastError = err
		m.mu.Unlock()
	}

	duration := time.Since(startTime)
	total, failed, toRemote, fromRemote, _ := m.stats.GetStats()

	if failed > 0 {
		logx.Errorf("âš ï¸  åŒæ­¥å®Œæˆ(æœ‰é”™è¯¯) - è€—æ—¶: %v, æ€»è®¡: %d, å¤±è´¥: %d, ä¸Šä¼ : %d, ä¸‹è½½: %d",
			duration, total, failed, toRemote, fromRemote)
	} else {
		logx.Infof("âœ… åŒæ­¥å®Œæˆ - è€—æ—¶: %v, æ€»è®¡: %d, ä¸Šä¼ : %d, ä¸‹è½½: %d",
			duration, total, toRemote, fromRemote)
	}
}

// åœæ­¢åŒæ­¥æœåŠ¡
func (m *DBSyncManager) Stop() error {
	m.mu.Lock()
	if m.status != SyncStatusRunning {
		m.mu.Unlock()
		return errors.New("sync manager not running")
	}
	m.mu.Unlock()

	logx.Info("ğŸ›‘ åœæ­¢æ•°æ®åº“åŒæ­¥æœåŠ¡...")
	m.cancel()

	m.mu.Lock()
	m.status = SyncStatusIdle
	m.mu.Unlock()

	logx.Info("âœ… æ•°æ®åº“åŒæ­¥æœåŠ¡å·²åœæ­¢")
	return nil
}

// æš‚åœåŒæ­¥
func (m *DBSyncManager) Pause() {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.status = SyncStatusPaused
	logx.Info("â¸ï¸  æš‚åœæ•°æ®åº“åŒæ­¥")
}

// æ¢å¤åŒæ­¥
func (m *DBSyncManager) Resume() {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.status = SyncStatusRunning
	logx.Info("â–¶ï¸  æ¢å¤æ•°æ®åº“åŒæ­¥")
}

// è§¦å‘ç«‹å³åŒæ­¥
func (m *DBSyncManager) TriggerSync() {
	select {
	case m.syncTrigger <- struct{}{}:
		logx.Info("ğŸ”” è§¦å‘ç«‹å³åŒæ­¥")
	default:
		// é€šé“å·²æ»¡ï¼Œè¯´æ˜æœ‰åŒæ­¥æ­£åœ¨æ’é˜Ÿ
	}
}

// è·å–åŒæ­¥çŠ¶æ€
func (m *DBSyncManager) GetStatus() (SyncStatus, error) {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.status, m.lastError
}

// è·å–ç»Ÿè®¡ä¿¡æ¯
func (m *DBSyncManager) GetStats() *SyncStats {
	return m.stats
}

// æ¸…é™¤é”™è¯¯
func (m *DBSyncManager) ClearError() {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.lastError = nil
	if m.status == SyncStatusError {
		m.status = SyncStatusIdle
	}
}

// è®°å½•å˜æ›´
func (m *DBSyncManager) LogChange(tableName, operation string, recordID interface{}, direction SyncDirection) {
	entry := &ChangeEntry{
		TableName: tableName,
		Operation: operation,
		RecordID:  recordID,
		Timestamp: time.Now(),
		Direction: direction,
	}
	m.changeLog.Add(entry)
}

// å˜æ›´æ—¥å¿—
type ChangeLog struct {
	mu      sync.RWMutex
	entries []*ChangeEntry
}

type ChangeEntry struct {
	TableName string
	Operation string
	RecordID  interface{}
	Timestamp time.Time
	Direction SyncDirection
}

func NewChangeLog() *ChangeLog {
	return &ChangeLog{
		entries: make([]*ChangeEntry, 0),
	}
}

func (cl *ChangeLog) Add(entry *ChangeEntry) {
	cl.mu.Lock()
	defer cl.mu.Unlock()
	cl.entries = append(cl.entries, entry)
}

func (cl *ChangeLog) GetPending() []*ChangeEntry {
	cl.mu.RLock()
	defer cl.mu.RUnlock()
	return append([]*ChangeEntry{}, cl.entries...)
}

func (cl *ChangeLog) Remove(tableName string, recordID interface{}, direction SyncDirection) {
	cl.mu.Lock()
	defer cl.mu.Unlock()

	filtered := make([]*ChangeEntry, 0)
	for _, entry := range cl.entries {
		if entry.TableName != tableName || entry.RecordID != recordID || entry.Direction != direction {
			filtered = append(filtered, entry)
		}
	}
	cl.entries = filtered
}

func (cl *ChangeLog) Clear() {
	cl.mu.Lock()
	defer cl.mu.Unlock()
	cl.entries = make([]*ChangeEntry, 0)
}
