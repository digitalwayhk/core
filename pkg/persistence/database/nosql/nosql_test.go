package nosql

import (
	"fmt"
	"testing"
	"time"

	"github.com/digitalwayhk/core/pkg/persistence/entity"
	"github.com/digitalwayhk/core/pkg/persistence/types"
	"github.com/digitalwayhk/core/pkg/utils"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

func init() {
	utils.TESTPATH = "/Users/vincent/Documents/å­˜æ¡£æ–‡ç¨¿/MyCode/digitalway.hk/core/pkg/persistence/database/nosql/testdata"
}

// TestModel å®ç° types.IModel æ¥å£
type TestModel struct {
	*entity.Model
	Name      string    `json:"name"`
	Value     int       `json:"value"`
	CreatedAt time.Time `json:"created_at"`
}

// ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ uint ç±»å‹çš„ ID
func NewTestModel(id uint) *TestModel {
	m := &TestModel{
		Model: entity.NewModel(),
	}
	m.ID = id
	return m
}
func (t *TestModel) NewModel() {
	if t.Model == nil {
		t.Model = entity.NewModel()
	}
}
func (t *TestModel) GetHash() string {
	hash := fmt.Sprintf("%d:%d", t.Value, t.ID)
	return hash
}

// âœ… æ³›å‹ç‰ˆæœ¬çš„ setup
func setupBadgerDBGeneric(t *testing.T) (*BadgerDB[TestModel], func()) {
	path := t.TempDir()
	db, err := NewBadgerDBFast[TestModel](path)
	require.NoError(t, err)

	cleanup := func() {
		db.Close()
	}

	return db, cleanup
}

// âœ… æµ‹è¯•æ³›å‹ Set/Get
func TestGeneric_SetGet(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	model := NewTestModel(1001)
	model.Name = "generic test"
	model.Value = 100
	model.CreatedAt = time.Now()

	// Set - ç±»å‹å®‰å…¨
	err := db.Set(model, 0)
	require.NoError(t, err)

	// Get - ä½¿ç”¨ GetHash() è·å– key
	result, err := db.Get(model.GetHash())
	require.NoError(t, err)
	assert.NotNil(t, result)
	assert.Equal(t, "generic test", result.Name)
	assert.Equal(t, 100, result.Value)
	assert.Equal(t, uint(1001), result.ID)
}

// âœ… æµ‹è¯•æ³›å‹ BatchInsert
func TestGeneric_BatchInsert(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	items := make([]*TestModel, 100)
	for i := 0; i < 100; i++ {
		model := NewTestModel(uint(2000 + i))
		model.Name = fmt.Sprintf("name_%d", i)
		model.Value = i
		model.CreatedAt = time.Now()
		items[i] = model
	}

	err := db.BatchInsert(items)
	require.NoError(t, err)

	// éªŒè¯ - ä½¿ç”¨ GetHash()
	testModel := items[50]
	result, err := db.Get(testModel.GetHash())
	require.NoError(t, err)
	assert.Equal(t, "name_50", result.Name)
	assert.Equal(t, 50, result.Value)
	assert.Equal(t, uint(2050), result.ID)
}

// âœ… æµ‹è¯•æ³›å‹åŒæ­¥åŠŸèƒ½
func TestGeneric_Sync(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// ç­‰å¾…è¡¨åˆ›å»º
	//time.Sleep(100 * time.Millisecond)

	// æ’å…¥æ•°æ®
	model := NewTestModel(4001)
	model.Name = "sync test 1"
	model.Value = 200
	model.CreatedAt = time.Now()

	err := db.Set(model, 0)
	require.NoError(t, err)

	// éªŒè¯åŒæ­¥æ ‡è®°
	count, err := db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, 1, count)

	// æ‰‹åŠ¨è§¦å‘åŒæ­¥
	err = db.ManualSync()
	require.NoError(t, err)

	// ç­‰å¾…åŒæ­¥å®Œæˆ
	time.Sleep(200 * time.Millisecond)

	// éªŒè¯æ•°æ®å·²åŒæ­¥åˆ° SQLite
	result, err := gormDB.SearchId(uint(4001))
	require.NoError(t, err)
	assert.Equal(t, "sync test 1", result.Name)
	assert.Equal(t, 200, result.Value)

	// éªŒè¯åŒæ­¥æ ‡è®°å·²åˆ é™¤
	count, err = db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, 0, count)
}

// âœ… æµ‹è¯•æ³›å‹ GetAll
func TestGeneric_GetAll(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	// æ’å…¥æ•°æ®
	for i := 0; i < 10; i++ {
		model := NewTestModel(uint(5000 + i))
		model.Name = fmt.Sprintf("name_%d", i)
		model.Value = i
		model.CreatedAt = time.Now()

		err := db.Set(model, 0)
		require.NoError(t, err)
	}

	// è·å–æ‰€æœ‰æ•°æ®
	results, err := db.GetAll()
	require.NoError(t, err)
	assert.Equal(t, 10, len(results))

	// ç±»å‹å®‰å…¨çš„éå†
	for _, item := range results {
		assert.Greater(t, item.ID, uint(0))
		assert.NotEmpty(t, item.Name)
	}
}

// âœ… æµ‹è¯• Delete
func TestGeneric_Delete(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	model := NewTestModel(6001)
	model.Name = "to be deleted"
	model.Value = 999

	// æ’å…¥
	err := db.Set(model, 0)
	require.NoError(t, err)

	key := model.GetHash()

	// éªŒè¯å­˜åœ¨
	result, err := db.Get(key)
	require.NoError(t, err)
	assert.Equal(t, "to be deleted", result.Name)

	// åˆ é™¤
	err = db.Delete(key)
	require.NoError(t, err)

	// éªŒè¯å·²åˆ é™¤
	_, err = db.Get(key)
	assert.Error(t, err)
}

// âœ… æµ‹è¯• TTL
func TestGeneric_TTL(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	model := NewTestModel(7001)
	model.Name = "will expire"
	model.Value = 777

	// è®¾ç½® 1 ç§’ TTL
	err := db.Set(model, 1*time.Second)
	require.NoError(t, err)

	key := model.GetHash()

	// ç«‹å³è¯»å–åº”è¯¥æˆåŠŸ
	result, err := db.Get(key)
	require.NoError(t, err)
	assert.Equal(t, "will expire", result.Name)

	// ç­‰å¾…è¿‡æœŸ
	time.Sleep(2 * time.Second)

	// åº”è¯¥è¯»å–å¤±è´¥
	_, err = db.Get(key)
	assert.Error(t, err)
}

// âœ… æµ‹è¯•ç©ºå€¼å¤„ç†
func TestGeneric_NilHandling(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	// æµ‹è¯•ç©ºæŒ‡é’ˆ
	var nilModel *TestModel
	err := db.Set(nilModel, 0)
	assert.Error(t, err)

	// æµ‹è¯•ç©ºåˆ‡ç‰‡
	err = db.BatchInsert([]*TestModel{})
	assert.NoError(t, err) // ç©ºåˆ‡ç‰‡åº”è¯¥ç›´æ¥è¿”å›æˆåŠŸ

	// æµ‹è¯•åŒ…å« nil çš„åˆ‡ç‰‡
	err = db.BatchInsert([]*TestModel{nil})
	assert.NoError(t, err)
}

// âœ… æµ‹è¯•å¹¶å‘å†™å…¥
func TestGeneric_ConcurrentWrites(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	const goroutines = 10
	const itemsPerGoroutine = 100

	done := make(chan bool, goroutines)

	for g := 0; g < goroutines; g++ {
		go func(gid int) {
			for i := 0; i < itemsPerGoroutine; i++ {
				model := NewTestModel(uint(8000 + gid*1000 + i))
				model.Name = fmt.Sprintf("concurrent_%d_%d", gid, i)
				model.Value = i

				err := db.Set(model, 0)
				if err != nil {
					t.Errorf("å¹¶å‘å†™å…¥å¤±è´¥: %v", err)
				}
			}
			done <- true
		}(g)
	}

	// ç­‰å¾…æ‰€æœ‰ goroutine å®Œæˆ
	for i := 0; i < goroutines; i++ {
		<-done
	}

	// éªŒè¯æ•°æ®å®Œæ•´æ€§
	results, err := db.GetAll()
	require.NoError(t, err)
	assert.Equal(t, goroutines*itemsPerGoroutine, len(results))
}

// âœ… åŸºå‡†æµ‹è¯• - æ³›å‹ç‰ˆæœ¬
func BenchmarkGeneric_Set(b *testing.B) {
	db, _ := NewBadgerDBFast[TestModel](b.TempDir())
	defer db.Close()

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		model := NewTestModel(uint(10000 + i))
		model.Name = "benchmark"
		model.Value = i
		model.CreatedAt = time.Now()

		db.Set(model, 0)
	}
}

func BenchmarkGeneric_Get(b *testing.B) {
	db, _ := NewBadgerDBFast[TestModel](b.TempDir())
	defer db.Close()

	// å‡†å¤‡æ•°æ®
	model := NewTestModel(11001)
	model.Name = "benchmark"
	model.Value = 999
	db.Set(model, 0)

	key := model.GetHash()

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		db.Get(key)
	}
}

func BenchmarkGeneric_BatchInsert_100(b *testing.B) {
	db, _ := NewBadgerDBFast[TestModel](b.TempDir())
	defer db.Close()

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		items := make([]*TestModel, 100)
		for j := 0; j < 100; j++ {
			model := NewTestModel(uint(12000 + i*100 + j))
			model.Name = fmt.Sprintf("name_%d", j)
			model.Value = j
			model.CreatedAt = time.Now()
			items[j] = model
		}
		db.BatchInsert(items)
	}
}

func BenchmarkGeneric_BatchInsert_1000(b *testing.B) {
	db, _ := NewBadgerDBFast[TestModel](b.TempDir())
	defer db.Close()

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		items := make([]*TestModel, 1000)
		for j := 0; j < 1000; j++ {
			model := NewTestModel(uint(13000 + i*1000 + j))
			model.Name = fmt.Sprintf("name_%d", j)
			model.Value = j
			model.CreatedAt = time.Now()
			items[j] = model
		}
		db.BatchInsert(items)
	}
}

// setupSQLite è¾…åŠ©å‡½æ•°
func setupSQLite(t *testing.T) (*entity.ModelList[TestModel], func()) {

	list := entity.NewModelList[TestModel](nil)
	// è‡ªåŠ¨è¿ç§»æµ‹è¯•æ¨¡å‹

	cleanup := func() {
		// if sqlDB, err := db.DB(); err == nil {
		// 	sqlDB.Close()
		// }
	}

	return list, cleanup
}

// ...existing code...

// âœ… æµ‹è¯•æ‰¹é‡åŒæ­¥åŠŸèƒ½
func TestGeneric_BatchSync(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ‰¹é‡æ’å…¥æ•°æ®
	const batchSize = 100
	items := make([]*TestModel, batchSize)
	for i := 0; i < batchSize; i++ {
		model := NewTestModel(uint(20000 + i))
		model.Name = fmt.Sprintf("batch_sync_%d", i)
		model.Value = i
		model.CreatedAt = time.Now()
		items[i] = model
	}

	err := db.BatchInsert(items)
	require.NoError(t, err)

	// éªŒè¯åŒæ­¥æ ‡è®°æ•°é‡
	count, err := db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, batchSize, count)

	// æ‰‹åŠ¨è§¦å‘åŒæ­¥
	err = db.ManualSync()
	require.NoError(t, err)

	// ç­‰å¾…åŒæ­¥å®Œæˆ
	time.Sleep(500 * time.Millisecond)

	result, _, err := gormDB.SearchAll(1, batchSize, func(item *types.SearchItem) {
		item.AddWhereNS("id", ">=", uint(20000))
		item.AddWhereNS("id", "<", uint(20000+batchSize))
	})
	require.NoError(t, err)
	assert.Equal(t, batchSize, len(result))

	// éªŒè¯æ•°æ®å®Œæ•´æ€§
	nameMap := make(map[string]bool)
	for _, r := range result {
		nameMap[r.Name] = true
	}
	assert.Equal(t, batchSize, len(nameMap))

	// éªŒè¯åŒæ­¥æ ‡è®°å·²å…¨éƒ¨åˆ é™¤
	count, err = db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, 0, count)
}

// âœ… æµ‹è¯•å¤§æ‰¹é‡åŒæ­¥ï¼ˆæµ‹è¯•åˆ†æ‰¹å¤„ç†ï¼‰
func TestGeneric_LargeBatchSync(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ’å…¥å¤§é‡æ•°æ®ï¼ˆè¶…è¿‡ maxSyncBatchSizeï¼‰
	const totalItems = 1500
	items := make([]*TestModel, totalItems)
	for i := 0; i < totalItems; i++ {
		model := NewTestModel(uint(21000 + i))
		model.Name = fmt.Sprintf("large_sync_%d", i)
		model.Value = i
		model.CreatedAt = time.Now()
		items[i] = model
	}

	// åˆ†æ‰¹æ’å…¥
	const insertBatchSize = 500
	for i := 0; i < totalItems; i += insertBatchSize {
		end := i + insertBatchSize
		if end > totalItems {
			end = totalItems
		}
		err := db.BatchInsert(items[i:end])
		require.NoError(t, err)
	}

	// éªŒè¯åŒæ­¥æ ‡è®°æ•°é‡
	count, err := db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, totalItems, count)

	// å¤šæ¬¡æ‰‹åŠ¨è§¦å‘åŒæ­¥ï¼ˆå› ä¸ºè¶…è¿‡äº† maxSyncBatchSizeï¼‰
	maxRetries := 5
	for retry := 0; retry < maxRetries; retry++ {
		err = db.ManualSync()
		require.NoError(t, err)

		time.Sleep(500 * time.Millisecond)

		count, err = db.GetPendingSyncCount()
		require.NoError(t, err)

		if count == 0 {
			break
		}

		t.Logf("åŒæ­¥è¿›åº¦: å‰©ä½™ %d æ¡å¾…åŒæ­¥", count)
	}

	// éªŒè¯æ‰€æœ‰åŒæ­¥æ ‡è®°å·²åˆ é™¤
	count, err = db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, 0, count, "åº”è¯¥æ²¡æœ‰å¾…åŒæ­¥çš„æ•°æ®")

	// éªŒè¯æ‰€æœ‰æ•°æ®å·²åŒæ­¥åˆ° SQLite

	result, _, err := gormDB.SearchAll(1, totalItems, func(item *types.SearchItem) {
		item.AddWhereNS("id", ">=", uint(21000))
		item.AddWhereNS("id", "<", uint(21000+totalItems))
	})

	require.NoError(t, err)
	assert.Equal(t, totalItems, len(result))
}

// âœ… æµ‹è¯•åŒæ­¥å¤±è´¥é‡è¯•
func TestGeneric_SyncRetry(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ’å…¥æ•°æ®
	model := NewTestModel(22001)
	model.Name = "retry_test"
	model.Value = 100
	model.CreatedAt = time.Now()

	err := db.Set(model, 0)
	require.NoError(t, err)

	// éªŒè¯åŒæ­¥æ ‡è®°
	count, err := db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, 1, count)
	// å…³é—­ SQLite æ•°æ®åº“ï¼ˆæ¨¡æ‹ŸåŒæ­¥å¤±è´¥ï¼‰
	if sqldb, err := gormDB.GetDB(); err == nil {
		// å…³é—­ SQLite æ•°æ®åº“è¿æ¥ä»¥æ¨¡æ‹ŸåŒæ­¥å¤±è´¥
		if sqldb != nil {
			idb, _ := sqldb.DB()
			if idb != nil {
				idb.Close()
			}
		}
	}

	// å°è¯•åŒæ­¥ï¼ˆåº”è¯¥å¤±è´¥ï¼‰
	err = db.ManualSync()
	// ä¸æ£€æŸ¥é”™è¯¯ï¼Œå› ä¸ºå®ç°å¯èƒ½ä¼šå¿½ç•¥é”™è¯¯

	// é‡æ–°æ‰“å¼€æ•°æ®åº“
	gormDB2, cleanupSQL2 := setupSQLite(t)
	defer cleanupSQL2()

	// é‡æ–°è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB2)

	// å†æ¬¡æ‰‹åŠ¨è§¦å‘åŒæ­¥ï¼ˆåº”è¯¥æˆåŠŸï¼‰
	err = db.ManualSync()
	require.NoError(t, err)

	time.Sleep(200 * time.Millisecond)

	// éªŒè¯æ•°æ®å·²åŒæ­¥
	result, err := gormDB2.SearchOne(func(item *types.SearchItem) {
		item.AddWhereN("id", uint(22001))
	})
	require.NoError(t, err)
	assert.Equal(t, "retry_test", result.Name)
}

// âœ… æµ‹è¯•å¹¶å‘å†™å…¥å’ŒåŒæ­¥
func TestGeneric_ConcurrentWriteAndSync(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	const goroutines = 5
	const itemsPerGoroutine = 50
	done := make(chan bool, goroutines)

	// å¹¶å‘å†™å…¥
	for g := 0; g < goroutines; g++ {
		go func(gid int) {
			for i := 0; i < itemsPerGoroutine; i++ {
				model := NewTestModel(uint(23000 + gid*1000 + i))
				model.Name = fmt.Sprintf("concurrent_sync_%d_%d", gid, i)
				model.Value = i

				err := db.Set(model, 0)
				if err != nil {
					t.Errorf("å¹¶å‘å†™å…¥å¤±è´¥: %v", err)
				}
			}
			done <- true
		}(g)
	}

	// ç­‰å¾…æ‰€æœ‰å†™å…¥å®Œæˆ
	for i := 0; i < goroutines; i++ {
		<-done
	}

	// éªŒè¯åŒæ­¥æ ‡è®°æ•°é‡
	count, err := db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, goroutines*itemsPerGoroutine, count)

	// å¤šæ¬¡æ‰‹åŠ¨è§¦å‘åŒæ­¥
	for retry := 0; retry < 3; retry++ {
		err = db.ManualSync()
		require.NoError(t, err)
		time.Sleep(300 * time.Millisecond)

		count, err = db.GetPendingSyncCount()
		require.NoError(t, err)
		if count == 0 {
			break
		}
	}

	// éªŒè¯æ‰€æœ‰æ•°æ®å·²åŒæ­¥
	result, _, err := gormDB.SearchAll(1, goroutines*itemsPerGoroutine, func(item *types.SearchItem) {
		item.AddWhereNS("id", ">=", uint(23000))
		item.AddWhereNS("id", "<", uint(23000+goroutines*1000))
	})
	require.NoError(t, err)
	assert.Equal(t, goroutines*itemsPerGoroutine, len(result))

	// éªŒè¯åŒæ­¥æ ‡è®°å·²å…¨éƒ¨åˆ é™¤
	count, err = db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, 0, count)
}

// âœ… æµ‹è¯•è‡ªåŠ¨åŒæ­¥ï¼ˆå®šæ—¶å™¨è§¦å‘ï¼‰
func TestGeneric_AutoSync(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ’å…¥æ•°æ®
	const itemCount = 20
	for i := 0; i < itemCount; i++ {
		model := NewTestModel(uint(24000 + i))
		model.Name = fmt.Sprintf("auto_sync_%d", i)
		model.Value = i
		model.CreatedAt = time.Now()

		err := db.Set(model, 0)
		require.NoError(t, err)
	}

	// éªŒè¯åŒæ­¥æ ‡è®°
	count, err := db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, itemCount, count)

	// ç­‰å¾…è‡ªåŠ¨åŒæ­¥ï¼ˆå®šæ—¶å™¨æ˜¯ 1 ç§’ï¼‰
	time.Sleep(3 * time.Second)

	// éªŒè¯æ•°æ®å·²è‡ªåŠ¨åŒæ­¥
	result, _, err := gormDB.SearchAll(1, itemCount, func(item *types.SearchItem) {
		item.AddWhereNS("id", ">=", uint(24000))
		item.AddWhereNS("id", "<", uint(24000+itemCount))
	})
	require.NoError(t, err)
	assert.Equal(t, itemCount, len(result))

	// éªŒè¯åŒæ­¥æ ‡è®°å·²åˆ é™¤
	count, err = db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, 0, count)
}

// âœ… æµ‹è¯•åˆ é™¤åçš„åŒæ­¥
func TestGeneric_DeleteSync(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ’å…¥æ•°æ®
	model := NewTestModel(25001)
	model.Name = "will_be_deleted"
	model.Value = 999
	model.CreatedAt = time.Now()

	err := db.Set(model, 0)
	require.NoError(t, err)

	key := model.GetHash()

	// ç«‹å³åˆ é™¤ï¼ˆåœ¨åŒæ­¥ä¹‹å‰ï¼‰
	err = db.Delete(key)
	require.NoError(t, err)

	// æ‰‹åŠ¨è§¦å‘åŒæ­¥
	err = db.ManualSync()
	require.NoError(t, err)

	time.Sleep(200 * time.Millisecond)

	// éªŒè¯æ•°æ®ä¸åº”è¯¥å­˜åœ¨äº SQLiteï¼ˆå› ä¸ºåœ¨åŒæ­¥å‰å·²åˆ é™¤ï¼‰
	result, err := gormDB.SearchId(uint(25001))
	require.NoError(t, err)
	assert.NotEmpty(t, 0, result)

	// éªŒè¯åŒæ­¥æ ‡è®°å·²åˆ é™¤
	count, err := db.GetPendingSyncCount()
	require.NoError(t, err)
	assert.Equal(t, 0, count)
}

// âœ… åŸºå‡†æµ‹è¯• - æ‰¹é‡åŒæ­¥æ€§èƒ½
func BenchmarkGeneric_BatchSync_100(b *testing.B) {
	db, _ := NewBadgerDBFast[TestModel](b.TempDir())
	defer db.Close()

	list := entity.NewModelList[TestModel](nil)
	db.SetSyncDB(list)

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		// æ‰¹é‡æ’å…¥ 100 æ¡
		items := make([]*TestModel, 100)
		for j := 0; j < 100; j++ {
			model := NewTestModel(uint(30000 + i*100 + j))
			model.Name = fmt.Sprintf("bench_sync_%d", j)
			model.Value = j
			items[j] = model
		}
		db.BatchInsert(items)
	}
}

func BenchmarkGeneric_BatchSync_1000(b *testing.B) {
	db, _ := NewBadgerDBFast[TestModel](b.TempDir())
	defer db.Close()

	list := entity.NewModelList[TestModel](nil)
	db.SetSyncDB(list)

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		// æ‰¹é‡æ’å…¥ 1000 æ¡
		items := make([]*TestModel, 1000)
		for j := 0; j < 1000; j++ {
			model := NewTestModel(uint(40000 + i*1000 + j))
			model.Name = fmt.Sprintf("bench_sync_%d", j)
			model.Value = j
			items[j] = model
		}
		db.BatchInsert(items)

		// è§¦å‘åŒæ­¥ï¼ˆå¯èƒ½éœ€è¦å¤šæ¬¡ï¼‰
		//db.ManualSync()
	}
}

// âœ… æµ‹è¯•è‡ªåŠ¨æ¸…ç†åŠŸèƒ½
func TestGeneric_AutoCleanup(t *testing.T) {
	// åˆ›å»ºå¸¦è‡ªåŠ¨æ¸…ç†é…ç½®çš„ BadgerDB
	config := DefaultProductionConfig(t.TempDir())
	config.AutoCleanup = true
	config.CleanupInterval = 500 * time.Millisecond
	config.KeepDuration = 1 * time.Second

	db, err := NewBadgerDBWithConfig[TestModel](config)
	db.config.SizeThreshold = 0
	require.NoError(t, err)
	defer db.Close()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ’å…¥å¹¶åŒæ­¥æ•°æ®
	model := NewTestModel(26001)
	model.Name = "cleanup_test"
	model.Value = 100
	model.CreatedAt = time.Now()

	err = db.Set(model, 0)
	require.NoError(t, err)

	// // æ‰‹åŠ¨è§¦å‘åŒæ­¥
	// err = db.ManualSync()
	// require.NoError(t, err)
	row, err := db.Get(model.GetHash())
	require.NoError(t, err)
	require.NotNil(t, row)
	require.Equal(t, "cleanup_test", row.Name)
	time.Sleep(600 * time.Millisecond)

	// éªŒè¯æ•°æ®å·²åŒæ­¥åˆ° SQLite
	result, err := gormDB.SearchId(uint(26001))
	require.NoError(t, err)
	assert.NotEmpty(t, result)

	// ç­‰å¾…è‡ªåŠ¨æ¸…ç†ï¼ˆCleanupKeepDuration + CleanupIntervalï¼‰
	// ç­‰å¾…æ•°æ®è¶…è¿‡ä¿ç•™æœŸé™ + æ¸…ç†é—´éš”è§¦å‘
	time.Sleep(2 * time.Second)

	// éªŒè¯ BadgerDB ä¸­çš„æ•°æ®å·²è¢«æ¸…ç†
	row, err = db.Get(model.GetHash())
	assert.Error(t, err, "Key not found")
	assert.Nil(t, row, "BadgerDB ä¸­çš„æ•°æ®åº”è¯¥è¢«æ¸…ç†")

	// éªŒè¯ SQLite ä¸­çš„æ•°æ®ä»ç„¶å­˜åœ¨
	result, err = gormDB.SearchId(uint(26001))
	require.NoError(t, err)
	assert.NotEmpty(t, result, "SQLite ä¸­çš„æ•°æ®åº”è¯¥ä¿ç•™")
}

// âœ… æµ‹è¯•æ‰‹åŠ¨æ¸…ç†åŠŸèƒ½
func TestGeneric_ManualCleanup(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ’å…¥å¤šæ¡æ•°æ®
	for i := 0; i < 10; i++ {
		model := NewTestModel(uint(27000 + i))
		model.Name = fmt.Sprintf("manual_cleanup_%d", i)
		model.Value = i
		model.CreatedAt = time.Now()

		err := db.Set(model, 0)
		require.NoError(t, err)
	}

	// æ‰‹åŠ¨è§¦å‘åŒæ­¥
	err := db.ManualSync()
	require.NoError(t, err)

	time.Sleep(300 * time.Millisecond)

	// éªŒè¯æ•°æ®å·²åŒæ­¥
	results, _, err := gormDB.SearchAll(1, 10, func(item *types.SearchItem) {
		item.AddWhereNS("id", ">=", uint(27000))
		item.AddWhereNS("id", "<", uint(27010))
	})
	require.NoError(t, err)
	assert.Equal(t, 10, len(results))

	// æ‰‹åŠ¨è§¦å‘æ¸…ç†ï¼ˆä¿ç•™ 0 ç§’ï¼Œå³ç«‹å³æ¸…ç†æ‰€æœ‰å·²åŒæ­¥æ•°æ®ï¼‰
	err = db.CleanupAfterSync(0)
	require.NoError(t, err)

	// éªŒè¯ BadgerDB ä¸­çš„æ•°æ®å·²è¢«æ¸…ç†
	allItems, err := db.GetAll()
	require.NoError(t, err)
	assert.Equal(t, 0, len(allItems), "æ‰€æœ‰å·²åŒæ­¥æ•°æ®åº”è¯¥è¢«æ¸…ç†")

	// éªŒè¯ SQLite ä¸­çš„æ•°æ®ä»ç„¶å­˜åœ¨
	results, _, err = gormDB.SearchAll(1, 10, func(item *types.SearchItem) {
		item.AddWhereNS("id", ">=", uint(27000))
		item.AddWhereNS("id", "<", uint(27010))
	})
	require.NoError(t, err)
	assert.Equal(t, 10, len(results), "SQLite ä¸­çš„æ•°æ®åº”è¯¥ä¿ç•™")
}

// âœ… æµ‹è¯•æ¸…ç†æœªåŒæ­¥çš„æ•°æ®ä¸ä¼šè¢«åˆ é™¤
func TestGeneric_CleanupPreservesUnsyncedData(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ’å…¥å·²åŒæ­¥çš„æ•°æ®
	syncedModel := NewTestModel(28001)
	syncedModel.Name = "synced_data"
	syncedModel.Value = 100

	err := db.Set(syncedModel, 0)
	require.NoError(t, err)

	// åŒæ­¥ç¬¬ä¸€æ¡æ•°æ®
	err = db.ManualSync()
	require.NoError(t, err)
	time.Sleep(200 * time.Millisecond)

	// æ’å…¥æœªåŒæ­¥çš„æ•°æ®
	unsyncedModel := NewTestModel(28002)
	unsyncedModel.Name = "unsynced_data"
	unsyncedModel.Value = 200

	err = db.Set(unsyncedModel, 0)
	require.NoError(t, err)

	// è§¦å‘æ¸…ç†
	err = db.CleanupAfterSync(0)
	require.NoError(t, err)

	// éªŒè¯å·²åŒæ­¥çš„æ•°æ®è¢«æ¸…ç†
	_, err = db.Get(syncedModel.GetHash())
	assert.Error(t, err, "å·²åŒæ­¥çš„æ•°æ®åº”è¯¥è¢«æ¸…ç†")

	// éªŒè¯æœªåŒæ­¥çš„æ•°æ®ä»ç„¶å­˜åœ¨
	result, err := db.Get(unsyncedModel.GetHash())
	require.NoError(t, err)
	assert.Equal(t, "unsynced_data", result.Name)
}

// âœ… æµ‹è¯•æ¸…ç†ä¿ç•™æœŸé™åŠŸèƒ½
func TestGeneric_CleanupWithKeepDuration(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ’å…¥æ—§æ•°æ®
	oldModel := NewTestModel(29001)
	oldModel.Name = "old_data"
	oldModel.Value = 100

	err := db.Set(oldModel, 0)
	require.NoError(t, err)

	// åŒæ­¥æ—§æ•°æ®
	err = db.ManualSync()
	require.NoError(t, err)
	time.Sleep(200 * time.Millisecond)

	// ç­‰å¾…ä¸€æ®µæ—¶é—´
	time.Sleep(1 * time.Second)

	// æ’å…¥æ–°æ•°æ®
	newModel := NewTestModel(29002)
	newModel.Name = "new_data"
	newModel.Value = 200

	err = db.Set(newModel, 0)
	require.NoError(t, err)

	// åŒæ­¥æ–°æ•°æ®
	err = db.ManualSync()
	require.NoError(t, err)
	time.Sleep(200 * time.Millisecond)

	// æ¸…ç†ä¿ç•™ 500ms çš„æ•°æ®
	err = db.CleanupAfterSync(500 * time.Millisecond)
	require.NoError(t, err)

	// æ—§æ•°æ®åº”è¯¥è¢«æ¸…ç†
	_, err = db.Get(oldModel.GetHash())
	assert.Error(t, err, "æ—§æ•°æ®åº”è¯¥è¢«æ¸…ç†")

	// æ–°æ•°æ®åº”è¯¥ä¿ç•™
	result, err := db.Get(newModel.GetHash())
	require.NoError(t, err)
	assert.Equal(t, "new_data", result.Name)
}

// âœ… æµ‹è¯•æ‰¹é‡æ¸…ç†æ€§èƒ½
func TestGeneric_BatchCleanupPerformance(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ‰¹é‡æ’å…¥å¤§é‡æ•°æ®
	const totalItems = 1000
	items := make([]*TestModel, totalItems)
	for i := 0; i < totalItems; i++ {
		model := NewTestModel(uint(30000 + i))
		model.Name = fmt.Sprintf("cleanup_perf_%d", i)
		model.Value = i
		items[i] = model
	}

	err := db.BatchInsert(items)
	require.NoError(t, err)

	// æ‰¹é‡åŒæ­¥
	for retry := 0; retry < 3; retry++ {
		err = db.ManualSync()
		require.NoError(t, err)
		time.Sleep(300 * time.Millisecond)

		count, _ := db.GetPendingSyncCount()
		if count == 0 {
			break
		}
	}

	// æµ‹é‡æ¸…ç†æ—¶é—´
	startTime := time.Now()
	err = db.CleanupAfterSync(0)
	require.NoError(t, err)
	cleanupDuration := time.Since(startTime)

	t.Logf("æ¸…ç† %d æ¡æ•°æ®è€—æ—¶: %v", totalItems, cleanupDuration)

	// éªŒè¯æ¸…ç†å®Œæˆ
	allItems, err := db.GetAll()
	require.NoError(t, err)
	assert.Equal(t, 0, len(allItems))

	// éªŒè¯æ€§èƒ½ï¼ˆåº”è¯¥åœ¨ 1 ç§’å†…å®Œæˆï¼‰
	assert.Less(t, cleanupDuration, 1*time.Second, "æ¸…ç†æ—¶é—´è¿‡é•¿")
}

// âœ… æµ‹è¯•å¹¶å‘æ¸…ç†
func TestGeneric_ConcurrentCleanup(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ’å…¥æ•°æ®
	for i := 0; i < 100; i++ {
		model := NewTestModel(uint(31000 + i))
		model.Name = fmt.Sprintf("concurrent_cleanup_%d", i)
		model.Value = i

		err := db.Set(model, 0)
		require.NoError(t, err)
	}

	// åŒæ­¥æ•°æ®
	err := db.ManualSync()
	require.NoError(t, err)
	time.Sleep(300 * time.Millisecond)

	// å¹¶å‘è§¦å‘æ¸…ç†
	const goroutines = 5
	done := make(chan bool, goroutines)
	errors := make(chan error, goroutines)

	for i := 0; i < goroutines; i++ {
		go func() {
			err := db.CleanupAfterSync(0)
			if err != nil {
				errors <- err
			}
			done <- true
		}()
	}

	// ç­‰å¾…æ‰€æœ‰æ¸…ç†å®Œæˆ
	for i := 0; i < goroutines; i++ {
		<-done
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
	select {
	case err := <-errors:
		t.Fatalf("å¹¶å‘æ¸…ç†å¤±è´¥: %v", err)
	default:
	}

	// éªŒè¯æ•°æ®å·²æ¸…ç†
	allItems, err := db.GetAll()
	require.NoError(t, err)
	assert.Equal(t, 0, len(allItems))
}

// âœ… æµ‹è¯•æ¸…ç†åˆ é™¤æ ‡è®°çš„æ•°æ®
func TestGeneric_CleanupDeletedData(t *testing.T) {
	db, cleanup := setupBadgerDBGeneric(t)
	defer cleanup()

	gormDB, cleanupSQL := setupSQLite(t)
	defer cleanupSQL()

	// è®¾ç½®åŒæ­¥æ•°æ®åº“
	db.SetSyncDB(gormDB)

	// æ’å…¥æ•°æ®
	model := NewTestModel(32001)
	model.Name = "to_be_deleted_and_cleaned"
	model.Value = 999

	err := db.Set(model, 0)
	require.NoError(t, err)

	// åˆ é™¤æ•°æ®ï¼ˆè½¯åˆ é™¤ï¼‰
	err = db.Delete(model.GetHash())
	require.NoError(t, err)

	// åŒæ­¥åˆ é™¤æ“ä½œ
	err = db.ManualSync()
	require.NoError(t, err)
	time.Sleep(200 * time.Millisecond)

	// æ¸…ç†
	err = db.CleanupAfterSync(0)
	require.NoError(t, err)

	// éªŒè¯å·²åˆ é™¤çš„æ•°æ®ä¹Ÿè¢«æ¸…ç†
	wrapper, err := db.getWrapper(model.GetHash())
	assert.Error(t, err, "å·²åˆ é™¤å¹¶åŒæ­¥çš„æ•°æ®åº”è¯¥è¢«å®Œå…¨æ¸…ç†")
	assert.Nil(t, wrapper)
}

// âœ… åŸºå‡†æµ‹è¯• - æ¸…ç†æ€§èƒ½
func BenchmarkGeneric_Cleanup_100(b *testing.B) {
	db, _ := NewBadgerDBFast[TestModel](b.TempDir())
	defer db.Close()

	list := entity.NewModelList[TestModel](nil)
	db.SetSyncDB(list)

	// å‡†å¤‡æ•°æ®
	items := make([]*TestModel, 100)
	for i := 0; i < 100; i++ {
		model := NewTestModel(uint(40000 + i))
		model.Name = fmt.Sprintf("bench_cleanup_%d", i)
		model.Value = i
		items[i] = model
	}
	db.BatchInsert(items)
	db.ManualSync()
	time.Sleep(200 * time.Millisecond)

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		db.CleanupAfterSync(0)
	}
}

func BenchmarkGeneric_Cleanup_1000(b *testing.B) {
	db, _ := NewBadgerDBFast[TestModel](b.TempDir())
	defer db.Close()

	list := entity.NewModelList[TestModel](nil)
	db.SetSyncDB(list)

	// å‡†å¤‡æ•°æ®
	items := make([]*TestModel, 1000)
	for i := 0; i < 1000; i++ {
		model := NewTestModel(uint(50000 + i))
		model.Name = fmt.Sprintf("bench_cleanup_%d", i)
		model.Value = i
		items[i] = model
	}
	db.BatchInsert(items)

	for retry := 0; retry < 3; retry++ {
		db.ManualSync()
		time.Sleep(200 * time.Millisecond)
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		db.CleanupAfterSync(0)
	}
}
