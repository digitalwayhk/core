package nosql

import (
	"fmt"
	"os"
	"path/filepath"
	"strconv"
	"strings"
	"sync"
	"syscall"
	"time"

	"github.com/digitalwayhk/core/pkg/json"

	"github.com/dgraph-io/badger/v3"
	"github.com/digitalwayhk/core/pkg/persistence/types"
	"github.com/zeromicro/go-zero/core/logx"
)

// BadgerDB æ³›å‹ KV æ•°æ®åº“
type BadgerDB[T any] struct {
	db      *badger.DB
	path    string
	config  BadgerDBConfig // ğŸ†• é…ç½®
	closeCh chan struct{}
	wg      sync.WaitGroup

	// âœ… æ·»åŠ å…³é—­çŠ¶æ€æ§åˆ¶
	closeOnce sync.Once
	closed    bool
	mu        sync.RWMutex // ä¿æŠ¤ closed å­—æ®µ
}

// NewBadgerDB åˆ›å»ºç”Ÿäº§ç¯å¢ƒ BadgerDBï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
func NewBadgerDB[T any](path string) (*BadgerDB[T], error) {
	config := DefaultProductionConfig(path)
	return NewBadgerDBWithConfig[T](config)
}

// NewBadgerDBFast åˆ›å»ºå¿«é€Ÿæ¨¡å¼ BadgerDBï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
func NewBadgerDBFast[T any](path string) (*BadgerDB[T], error) {
	config := DefaultFastConfig(path)
	config.PeriodicSync = true
	return NewBadgerDBWithConfig[T](config)
}

// ğŸ†• æ£€æŸ¥å¹¶è¯Šæ–­é”å®šé”™è¯¯
func diagnoseLockError(dbPath string) string {
	lockFile := filepath.Join(dbPath, "LOCK")

	// æ£€æŸ¥é”æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if _, err := os.Stat(lockFile); os.IsNotExist(err) {
		return "é”æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆå¯èƒ½æ˜¯å…¶ä»–é”™è¯¯ï¼‰"
	}

	// å°è¯•è¯»å–é”æ–‡ä»¶å†…å®¹ï¼ˆBadgerDB ä¼šå†™å…¥è¿›ç¨‹ä¿¡æ¯ï¼‰
	content, err := os.ReadFile(lockFile)
	if err != nil {
		return fmt.Sprintf("æ— æ³•è¯»å–é”æ–‡ä»¶: %v", err)
	}

	// è§£æé”æ–‡ä»¶å†…å®¹
	lines := strings.Split(string(content), "\n")
	if len(lines) > 0 && lines[0] != "" {
		pid, err := strconv.Atoi(strings.TrimSpace(lines[0]))
		if err == nil {
			// æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
			process, err := os.FindProcess(pid)
			if err != nil {
				return fmt.Sprintf("é”å®šè¿›ç¨‹ PID=%d å·²ä¸å­˜åœ¨ï¼ˆå¯èƒ½æ˜¯åƒµå°¸é”ï¼‰", pid)
			}

			// å°è¯•å‘é€ä¿¡å· 0 æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜æ´»
			err = process.Signal(syscall.Signal(0))
			if err != nil {
				return fmt.Sprintf("é”å®šè¿›ç¨‹ PID=%d å·²ä¸å­˜åœ¨ï¼ˆåƒµå°¸é”ï¼‰ï¼Œå»ºè®®æ‰‹åŠ¨åˆ é™¤é”æ–‡ä»¶", pid)
			}

			// ğŸ”§ è·å–è¿›ç¨‹ä¿¡æ¯ï¼ˆmacOS/Linuxï¼‰
			processInfo := getProcessInfo(pid)
			return fmt.Sprintf("æ•°æ®åº“è¢«è¿›ç¨‹é”å®š [PID=%d, %s]", pid, processInfo)
		}
	}

	return fmt.Sprintf("é”æ–‡ä»¶å­˜åœ¨ä½†æ ¼å¼å¼‚å¸¸: %s", string(content))
}

// ğŸ†• è·å–è¿›ç¨‹ä¿¡æ¯
func getProcessInfo(pid int) string {
	// Linux: è¯»å– /proc ç›®å½•
	cmdPath := fmt.Sprintf("/proc/%d/cmdline", pid)
	if content, err := os.ReadFile(cmdPath); err == nil {
		cmd := strings.ReplaceAll(string(content), "\x00", " ")
		return fmt.Sprintf("å‘½ä»¤: %s", cmd)
	}

	// macOS/Unix: ä½¿ç”¨ ps å‘½ä»¤ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
	// æ³¨æ„ï¼šä¸ºé¿å…å¼•å…¥ os/exec ä¾èµ–ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
	// å®é™…ç”Ÿäº§ç¯å¢ƒå¯ä»¥ä½¿ç”¨ exec.Command("ps", "-p", strconv.Itoa(pid), "-o", "comm=")

	return "è¿›ç¨‹æ­£åœ¨è¿è¡Œ"
}

// ğŸ”§ æ”¹è¿›çš„é”å®šé”™è¯¯æ£€æŸ¥
func isLockError(err error) bool {
	if err == nil {
		return false
	}

	errStr := err.Error()

	// BadgerDB çš„å…¸å‹é”å®šé”™è¯¯ä¿¡æ¯
	lockKeywords := []string{
		"Cannot acquire directory lock",
		"resource temporarily unavailable",
		"å¦ä¸€ä¸ªè¿›ç¨‹æ­£åœ¨ä½¿ç”¨",
		"LOCK",
	}

	for _, keyword := range lockKeywords {
		if strings.Contains(errStr, keyword) {
			return true
		}
	}

	// ç³»ç»Ÿçº§é”å®šé”™è¯¯
	return os.IsExist(err) ||
		syscall.EAGAIN.Error() == errStr ||
		os.IsPermission(err)
}

// NewBadgerDBWithConfig ä½¿ç”¨é…ç½®åˆ›å»º BadgerDB
func NewBadgerDBWithConfig[T any](config BadgerDBConfig) (*BadgerDB[T], error) {
	// éªŒè¯é…ç½®
	if err := config.Validate(); err != nil {
		return nil, fmt.Errorf("é…ç½®éªŒè¯å¤±è´¥: %w", err)
	}

	// ğŸ†• å°è¯•æ¸…ç†æ—§çš„é”æ–‡ä»¶ï¼ˆä»…åœ¨å¼€å‘/æµ‹è¯•ç¯å¢ƒï¼‰
	if config.Mode == "fast" || config.Mode == "test" {
		lockFile := filepath.Join(config.Path, "LOCK")
		if _, err := os.Stat(lockFile); err == nil {
			// ğŸ”§ å…ˆè¯Šæ–­é”å®šæƒ…å†µ
			diagnosis := diagnoseLockError(config.Path)
			logx.Infof("å‘ç°é”æ–‡ä»¶: %s", diagnosis)

			// å°è¯•åˆ é™¤é”æ–‡ä»¶ï¼ˆå¯èƒ½å¤±è´¥ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼‰
			if err := os.Remove(lockFile); err != nil {
				logx.Errorf("æ— æ³•åˆ é™¤é”æ–‡ä»¶: %v", err)
			} else {
				logx.Info("å·²æ¸…ç†æ—§é”æ–‡ä»¶")
			}
		}
	}

	// æ„å»º BadgerDB é€‰é¡¹
	opts := badger.DefaultOptions(config.Path).
		WithSyncWrites(config.SyncWrites).
		WithDetectConflicts(config.DetectConflicts).
		WithNumVersionsToKeep(1).
		WithNumCompactors(config.NumCompactors).
		WithCompactL0OnClose(true).
		WithNumLevelZeroTables(config.NumLevelZeroTables).
		WithNumLevelZeroTablesStall(config.NumLevelZeroStall).
		WithValueLogFileSize(config.ValueLogFileSize).
		WithMemTableSize(config.MemTableSize).
		WithValueThreshold(config.ValueThreshold)

	// é…ç½®æ—¥å¿—
	if config.EnableLogger {
		opts = opts.WithLogger(&badgerLogger{})
	} else {
		opts = opts.WithLogger(nil)
	}

	// ğŸ†• æ·»åŠ é‡è¯•é€»è¾‘
	var db *badger.DB
	var err error
	maxRetries := 3

	for i := 0; i < maxRetries; i++ {
		db, err = badger.Open(opts)
		if err == nil {
			break
		}

		// æ£€æŸ¥æ˜¯å¦æ˜¯é”å®šé”™è¯¯
		if isLockError(err) {
			// ğŸ”§ è¯¦ç»†è¯Šæ–­
			diagnosis := diagnoseLockError(config.Path)

			if i < maxRetries-1 {
				logx.Errorf("æ•°æ®åº“è¢«é”å®šï¼Œç­‰å¾…é‡è¯•... (%d/%d)\nè¯¦æƒ…: %s", i+1, maxRetries, diagnosis)
				time.Sleep(time.Second * time.Duration(i+1))
				continue
			} else {
				// ğŸ”§ æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼Œè¿”å›è¯¦ç»†é”™è¯¯
				return nil, fmt.Errorf("æ‰“å¼€ BadgerDB å¤±è´¥ï¼ˆå·²é‡è¯• %d æ¬¡ï¼‰: %s\nåŸå§‹é”™è¯¯: %w",
					maxRetries, diagnosis, err)
			}
		}

		return nil, fmt.Errorf("æ‰“å¼€ BadgerDB å¤±è´¥: %w", err)
	}

	b := &BadgerDB[T]{
		db:      db,
		path:    config.Path,
		config:  config,
		closeCh: make(chan struct{}),
	}

	// å¯åŠ¨ GC
	b.wg.Add(1)
	go b.runGC()

	logx.Infof("BadgerDB å·²å¯åŠ¨ [mode=%s, path=%s, autoSync=%v, autoCleanup=%v]",
		config.Mode, config.Path, config.AutoSync, config.AutoCleanup)

	return b, nil
}

// ğŸ†• æ·»åŠ æ‰‹åŠ¨æ£€æŸ¥é”å®šçŠ¶æ€çš„æ–¹æ³•
func CheckDatabaseLock(dbPath string) error {
	lockFile := filepath.Join(dbPath, "LOCK")

	if _, err := os.Stat(lockFile); os.IsNotExist(err) {
		return nil // æ— é”
	}

	diagnosis := diagnoseLockError(dbPath)
	return fmt.Errorf("æ•°æ®åº“å·²è¢«é”å®š: %s", diagnosis)
}

// ğŸ†• å¼ºåˆ¶é‡Šæ”¾é”ï¼ˆå±é™©æ“ä½œï¼Œä»…ç”¨äºæ¢å¤ï¼‰
func ForceUnlock(dbPath string) error {
	lockFile := filepath.Join(dbPath, "LOCK")

	// å…ˆè¯Šæ–­
	diagnosis := diagnoseLockError(dbPath)
	logx.Errorf("å¼ºåˆ¶è§£é”å‰è¯Šæ–­: %s", diagnosis)

	// åˆ é™¤é”æ–‡ä»¶
	if err := os.Remove(lockFile); err != nil {
		return fmt.Errorf("åˆ é™¤é”æ–‡ä»¶å¤±è´¥: %w", err)
	}

	logx.Info("å·²å¼ºåˆ¶åˆ é™¤é”æ–‡ä»¶")
	return nil
}

// generateKey ç”Ÿæˆ key
func (b *BadgerDB[T]) generateKey(item *T) string {
	if item == nil {
		return ""
	}
	if rowCode, ok := any(item).(types.IRowCode); ok {
		return rowCode.GetHash()
	}
	return ""
}

// Set å†™å…¥æ•°æ®
func (b *BadgerDB[T]) Set(key string, item *T, ttl time.Duration, fn ...func(oldItem *T)) error {
	if err := b.checkClosed(); err != nil {
		return err
	}
	if key == "" {
		key = b.generateKey(item) // âœ… ä¿®å¤ï¼šä½¿ç”¨ = è€Œä¸æ˜¯ :=
		if key == "" {
			return badger.ErrEmptyKey
		}
	}
	data, err := b.setItem(key, item, fn...)
	if err != nil {
		return err
	}
	err = b.db.Update(func(txn *badger.Txn) error {
		entry := badger.NewEntry([]byte(key), data)
		if ttl > 0 {
			entry = entry.WithTTL(ttl)
		}
		return txn.SetEntry(entry)
	})
	return err
}
func (b *BadgerDB[T]) setItem(key string, item *T, fn ...func(old *T)) ([]byte, error) {
	if item == nil {
		return nil, fmt.Errorf("item ä¸èƒ½ä¸ºç©º")
	}
	existingWrapper, err := b.getWrapper(key)
	// âœ… ä¿®å¤ï¼šå¿½ç•¥ key ä¸å­˜åœ¨çš„é”™è¯¯æ˜¯æ­£å¸¸çš„
	if err != nil && err != badger.ErrKeyNotFound {
		return nil, fmt.Errorf("è·å–ç°æœ‰æ•°æ®å¤±è´¥: %w", err)
	}

	if len(fn) > 0 && existingWrapper != nil {
		fn[0](existingWrapper)
	}

	data, err := json.Marshal(item)
	if err != nil {
		return nil, fmt.Errorf("åºåˆ—åŒ–å¤±è´¥: %w", err)
	}
	return data, nil
}
func (b *BadgerDB[T]) batchInsert(items []*T, fn ...func(wrapper *T)) error {
	if len(items) == 0 {
		return nil
	}

	type serializedItem struct {
		key   string
		value []byte
	}

	serialized := make([]serializedItem, 0, len(items))

	for _, item := range items {
		if item == nil {
			continue
		}
		key := b.generateKey(item)
		if key == "" {
			return badger.ErrEmptyKey
		}
		value, err := b.setItem(key, item, fn...)
		if err != nil {
			return fmt.Errorf("åºåˆ—åŒ–å¤±è´¥: %w", err)
		}
		serialized = append(serialized, serializedItem{
			key:   key,
			value: value,
		})
	}

	// æ‰¹é‡å†™å…¥
	const maxRetries = 3
	var lastErr error

	for retry := 0; retry < maxRetries; retry++ {
		txn := b.db.NewTransaction(true)
		success := true

		for _, si := range serialized {
			if err := txn.Set([]byte(si.key), si.value); err != nil {
				if err == badger.ErrTxnTooBig {
					if commitErr := txn.Commit(); commitErr != nil {
						lastErr = commitErr
						success = false
						break
					}
					txn = b.db.NewTransaction(true)
					if err := txn.Set([]byte(si.key), si.value); err != nil {
						txn.Discard()
						lastErr = err
						success = false
						break
					}
				} else {
					txn.Discard()
					lastErr = err
					success = false
					break
				}
			}
		}

		if success {
			if err := txn.Commit(); err != nil {
				lastErr = err
				time.Sleep(time.Millisecond * 100 * time.Duration(retry+1))
				continue
			}
			return nil
		}

		txn.Discard()
		time.Sleep(time.Millisecond * 100 * time.Duration(retry+1))
	}

	return lastErr
}

// BatchInsert æ‰¹é‡æ’å…¥
func (b *BadgerDB[T]) BatchInsert(items []*T) error {
	if err := b.checkClosed(); err != nil {
		return err
	}
	return b.batchInsert(items)
}

// BatchInsertWithBack å¸¦å›è°ƒçš„æ‰¹é‡æ’å…¥
func (b *BadgerDB[T]) BatchInsertWithBack(items []*T, fn ...func(wrapper *T)) error {
	return b.batchInsert(items, fn...)
}
func (b *BadgerDB[T]) DeleteByItem(item *T) error {
	if item == nil {
		return fmt.Errorf("item ä¸èƒ½ä¸ºç©º")
	}
	key := b.generateKey(item)
	if key == "" {
		return badger.ErrEmptyKey
	}
	return b.delete(key)
}
func (b *BadgerDB[T]) DeleteByItemWithSync(item *T, needSync bool) error {
	if item == nil {
		return fmt.Errorf("item ä¸èƒ½ä¸ºç©º")
	}
	key := b.generateKey(item)
	if key == "" {
		return badger.ErrEmptyKey
	}
	// âœ… ä¿®å¤ï¼šä½¿ç”¨ needSync å‚æ•°
	if err := b.delete(key); err != nil {
		return err
	}
	// å¦‚æœéœ€è¦åŒæ­¥ï¼Œç«‹å³åˆ·æ–°åˆ°ç£ç›˜
	if needSync {
		return b.db.Sync()
	}
	return nil
}

// Delete åˆ é™¤æ•°æ®ï¼ˆæ”¯æŒè½¯åˆ é™¤ï¼‰
func (b *BadgerDB[T]) Delete(key string) error {
	if err := b.checkClosed(); err != nil {
		return err
	}
	return b.delete(key)
}
func (b *BadgerDB[T]) delete(key string) error {
	// ğŸ”§ ä¸éœ€è¦åŒæ­¥ï¼Œç›´æ¥ç‰©ç†åˆ é™¤
	return b.db.Update(func(txn *badger.Txn) error {
		return txn.Delete([]byte(key))
	})
}

// Get è·å–æ•°æ®ï¼ˆè¿‡æ»¤å·²åˆ é™¤çš„æ•°æ®ï¼‰
func (b *BadgerDB[T]) Get(key string) (*T, error) {
	if err := b.checkClosed(); err != nil {
		return nil, err
	}
	wrapper, err := b.getWrapper(key)
	if err != nil {
		return nil, err
	}

	return wrapper, nil
}

// getWrapper è·å–åŒ…è£…å¯¹è±¡ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
func (b *BadgerDB[T]) getWrapper(key string) (*T, error) {
	var wrapper = new(T)

	err := b.db.View(func(txn *badger.Txn) error {
		item, err := txn.Get([]byte(key))
		if err != nil {
			return err
		}

		return item.Value(func(val []byte) error {
			return json.Unmarshal(val, wrapper)
		})
	})

	if err != nil {
		return nil, err
	}

	return wrapper, nil
}
func (b *BadgerDB[T]) ScanWithFn(prefix string, fn func(item *T) bool) ([]*T, error) {
	var results []*T
	err := b.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = true
		it := txn.NewIterator(opts)
		defer it.Close()

		for it.Seek([]byte(prefix)); it.ValidForPrefix([]byte(prefix)); it.Next() {
			item := it.Item()

			err := item.Value(func(val []byte) error {
				var wrapper T
				if err := json.Unmarshal(val, &wrapper); err != nil {
					return err
				}
				if fn != nil {
					if fn(&wrapper) {
						results = append(results, &wrapper)
					}
				} else {
					results = append(results, &wrapper)
				}
				return nil
			})

			if err != nil {
				logx.Errorf("è§£ææ•°æ®å¤±è´¥: %v", err)
				continue
			}
		}
		return nil
	})
	return results, err
}

// Scan æ‰«ææ•°æ®
func (b *BadgerDB[T]) Scan(prefix string, limit int) ([]*T, error) {
	var results []*T

	err := b.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchSize = 100
		opts.PrefetchValues = true
		it := txn.NewIterator(opts)
		defer it.Close()

		count := 0
		for it.Seek([]byte(prefix)); it.ValidForPrefix([]byte(prefix)); it.Next() {
			// âœ… ä¿®å¤ï¼šlimit <= 0 è¡¨ç¤ºä¸é™åˆ¶
			if limit > 0 && count >= limit {
				break
			}
			item := it.Item()

			err := item.Value(func(val []byte) error {
				var wrapper T
				if err := json.Unmarshal(val, &wrapper); err != nil {
					return err
				}
				results = append(results, &wrapper)
				count++
				return nil
			})

			if err != nil {
				logx.Errorf("è§£ææ•°æ®å¤±è´¥: %v", err)
				continue
			}
		}
		return nil
	})

	return results, err
}

// GetAll è·å–æ‰€æœ‰æ•°æ®ï¼ˆè¿‡æ»¤å·²åˆ é™¤çš„æ•°æ®ï¼‰
func (b *BadgerDB[T]) GetAll() ([]*T, error) {
	var results []*T

	err := b.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = true
		it := txn.NewIterator(opts)
		defer it.Close()

		for it.Rewind(); it.Valid(); it.Next() {
			item := it.Item()

			err := item.Value(func(val []byte) error {
				var wrapper T
				if err := json.Unmarshal(val, &wrapper); err != nil {
					return err
				}

				results = append(results, &wrapper)
				return nil
			})

			if err != nil {
				logx.Errorf("è§£ææ•°æ®å¤±è´¥: %v", err)
				continue
			}
		}
		return nil
	})

	return results, err
}

// runGC åƒåœ¾å›æ”¶
func (b *BadgerDB[T]) runGC() {
	defer b.wg.Done()

	// ğŸ”§ ä½¿ç”¨é…ç½®ä¸­çš„ GC é—´éš”
	ticker := time.NewTicker(b.config.GCInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			var reclaimed int
			// âœ… ä¿®å¤ï¼šé™åˆ¶ GC å¾ªç¯æ¬¡æ•°å¹¶æ£€æŸ¥å…³é—­ä¿¡å·
			maxGCRuns := 10 // æ¯æ¬¡æœ€å¤šè¿è¡Œ 10 è½® GC
			for i := 0; i < maxGCRuns; i++ {
				// æ£€æŸ¥æ˜¯å¦éœ€è¦é€€å‡º
				select {
				case <-b.closeCh:
					logx.Info("runGC åœ¨ GC å¾ªç¯ä¸­æ”¶åˆ°é€€å‡ºä¿¡å·")
					return
				default:
				}

				err := b.db.RunValueLogGC(b.config.GCDiscardRatio)
				if err != nil {
					break
				}
				reclaimed++
			}
			if reclaimed > 0 {
				logx.Infof("GC å®Œæˆï¼Œå›æ”¶ %d ä¸ªæ–‡ä»¶", reclaimed)
			}
		case <-b.closeCh:
			logx.Info("runGC é€€å‡º")
			return
		}
	}
}

// Close å…³é—­æ•°æ®åº“
func (b *BadgerDB[T]) Close() error {
	return b.CloseWithTimeout(10*time.Second, 5*time.Second)
}

// CloseWithTimeout å¸¦è¶…æ—¶çš„å…³é—­æ•°æ®åº“ï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰
func (b *BadgerDB[T]) CloseWithTimeout(waitTimeout, syncTimeout time.Duration) error {
	var err error

	// âœ… ä½¿ç”¨ sync.Once ç¡®ä¿åªå…³é—­ä¸€æ¬¡
	b.closeOnce.Do(func() {
		// æ ‡è®°ä¸ºå·²å…³é—­
		b.mu.Lock()
		b.closed = true
		b.mu.Unlock()

		// å…³é—­ channelï¼Œé€šçŸ¥æ‰€æœ‰ goroutine é€€å‡º
		close(b.closeCh)

		// ç­‰å¾… goroutine é€€å‡ºï¼ˆå¸¦è¶…æ—¶ï¼‰
		done := make(chan struct{})
		go func() {
			b.wg.Wait()
			close(done)
		}()

		select {
		case <-done:
			logx.Info("åå° goroutine å·²å…¨éƒ¨é€€å‡º")
		case <-time.After(waitTimeout):
			logx.Errorf("ç­‰å¾…åå° goroutine é€€å‡ºè¶…æ—¶ï¼ˆ%vï¼‰ï¼Œå¼ºåˆ¶å…³é—­", waitTimeout)
		}

		// Sync æ“ä½œï¼ˆå¸¦è¶…æ—¶ï¼‰
		syncDone := make(chan error, 1)
		go func() {
			syncDone <- b.db.Sync()
		}()

		select {
		case syncErr := <-syncDone:
			if syncErr != nil {
				logx.Errorf("å…³é—­å‰ sync å¤±è´¥: %v", syncErr)
			}
		case <-time.After(syncTimeout):
			logx.Errorf("sync æ“ä½œè¶…æ—¶ï¼ˆ%vï¼‰ï¼Œç»§ç»­å…³é—­", syncTimeout)
		}

		// å…³é—­æ•°æ®åº“
		if closeErr := b.db.Close(); closeErr != nil {
			err = fmt.Errorf("å…³é—­ BadgerDB å¤±è´¥: %w", closeErr)
			return
		}

		logx.Info("BadgerDB å·²å…³é—­")
	})

	// å¦‚æœå·²ç»å…³é—­è¿‡ï¼Œè¿”å›æç¤º
	b.mu.RLock()
	alreadyClosed := b.closed
	b.mu.RUnlock()

	if alreadyClosed && err == nil {
		// ä¸æ˜¯ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œä½†ä¹‹å‰æˆåŠŸå…³é—­äº†
		return nil
	}

	return err
}

// IsClosed æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å…³é—­
func (b *BadgerDB[T]) IsClosed() bool {
	b.mu.RLock()
	defer b.mu.RUnlock()
	return b.closed
}

// checkClosed æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å…³é—­ï¼Œå¦‚æœå·²å…³é—­è¿”å›é”™è¯¯
func (b *BadgerDB[T]) checkClosed() error {
	if b.IsClosed() {
		return fmt.Errorf("æ•°æ®åº“å·²å…³é—­")
	}
	return nil
}

// min/max è¾…åŠ©å‡½æ•°
func min(a, b time.Duration) time.Duration {
	if a < b {
		return a
	}
	return b
}

func max(a, b time.Duration) time.Duration {
	if a > b {
		return a
	}
	return b
}

// DropAll åˆ é™¤æ‰€æœ‰æ•°æ®ï¼ˆå±é™©æ“ä½œï¼‰
func (b *BadgerDB[T]) DropAll() error {
	return b.db.DropAll()
}

// GetDBSize è·å–æ•°æ®åº“å¤§å°
func (b *BadgerDB[T]) GetDBSize() (int64, int64, error) {
	lsm, vlog := b.db.Size()
	return lsm, vlog, nil
}

// GetStats è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
func (b *BadgerDB[T]) GetStats() string {
	lsm, vlog := b.db.Size()
	return fmt.Sprintf("LSM å¤§å°: %d MB, VLog å¤§å°: %d MB", lsm/(1024*1024), vlog/(1024*1024))
}

// GetConfig è·å–å½“å‰é…ç½®
func (b *BadgerDB[T]) GetConfig() BadgerDBConfig {
	return b.config
}

// UpdateConfig æ›´æ–°é…ç½®ï¼ˆéƒ¨åˆ†å‚æ•°ï¼‰
func (b *BadgerDB[T]) UpdateConfig(updateFn func(*BadgerDBConfig)) error {

	oldConfig := b.config
	updateFn(&b.config)

	if err := b.config.Validate(); err != nil {
		b.config = oldConfig
		return fmt.Errorf("é…ç½®æ›´æ–°å¤±è´¥: %w", err)
	}

	logx.Infof("é…ç½®å·²æ›´æ–°: %+v", b.config)
	return nil
}

// CountAll è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ•°æ®æ€»æ•°ï¼ˆåŒ…æ‹¬å·²åˆ é™¤çš„æ•°æ®ï¼‰
func (b *BadgerDB[T]) Count() (int, error) {
	count := 0

	err := b.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = false // ä¸éœ€è¦è¯»å–å€¼
		it := txn.NewIterator(opts)
		defer it.Close()

		for it.Rewind(); it.Valid(); it.Next() {
			count++
		}
		return nil
	})

	return count, err
}

// CountByPrefix ç»Ÿè®¡æŒ‡å®šå‰ç¼€çš„æ•°æ®æ•°é‡ï¼ˆä¸åŒ…æ‹¬å·²åˆ é™¤ï¼‰
func (b *BadgerDB[T]) CountByPrefix(prefix string) (int, error) {
	count := 0

	err := b.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = true
		it := txn.NewIterator(opts)
		defer it.Close()

		for it.Seek([]byte(prefix)); it.ValidForPrefix([]byte(prefix)); it.Next() {
			item := it.Item()

			err := item.Value(func(val []byte) error {
				var wrapper T
				if err := json.Unmarshal(val, &wrapper); err != nil {
					return nil
				}
				count++

				return nil
			})

			if err != nil {
				continue
			}
		}
		return nil
	})

	return count, err
}

// GetStatistics è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
func (b *BadgerDB[T]) GetStatistics() (*DBStatistics, error) {
	stats := &DBStatistics{}

	err := b.db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		opts.PrefetchValues = true
		it := txn.NewIterator(opts)
		defer it.Close()

		for it.Rewind(); it.Valid(); it.Next() {
			item := it.Item()

			err := item.Value(func(val []byte) error {
				var wrapper T
				if err := json.Unmarshal(val, &wrapper); err != nil {
					return nil
				}

				stats.TotalCount++
				return nil
			})

			if err != nil {
				continue
			}
		}
		return nil
	})

	if err != nil {
		return nil, err
	}

	// è·å–æ•°æ®åº“å¤§å°
	lsm, vlog, _ := b.GetDBSize()
	stats.LSMSize = lsm
	stats.VLogSize = vlog
	stats.TotalSize = lsm + vlog

	return stats, nil
}

// DBStatistics æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
type DBStatistics struct {
	TotalCount int   `json:"total_count"` // æ€»æ•°æ®é‡
	LSMSize    int64 `json:"lsm_size"`    // LSM å¤§å°ï¼ˆå­—èŠ‚ï¼‰
	VLogSize   int64 `json:"vlog_size"`   // VLog å¤§å°ï¼ˆå­—èŠ‚ï¼‰
	TotalSize  int64 `json:"total_size"`  // æ€»å¤§å°ï¼ˆå­—èŠ‚ï¼‰
}

// String æ ¼å¼åŒ–è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
func (s *DBStatistics) String() string {
	return fmt.Sprintf(
		"æ€»æ•°: %d, LSM: %dMB, VLog: %dMB, æ€»å¤§å°: %dMB",
		s.TotalCount,
		s.LSMSize/(1024*1024),
		s.VLogSize/(1024*1024),
		s.TotalSize/(1024*1024),
	)
}
